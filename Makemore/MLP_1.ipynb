{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5c25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/TCH_1BHY58I?t=1868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102bb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092f59bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c9218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c503b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i + 1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f4c49",
   "metadata": {},
   "source": [
    "# #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ca1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    \n",
    "    # iterates through the words building lists of the 3 characters that preceed\n",
    "    # the given character, fills in the 0s ('.')\n",
    "    for ch in w + '.':  # add the final stop character\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        \n",
    "        # grabs the last 2 characters and makes them first, then the \n",
    "        # most recent character becomes the final character index\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80212b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8671e5",
   "metadata": {},
   "source": [
    "## Build the Lookup Table (embedding space)\n",
    "27 characters into ___ Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f09a21",
   "metadata": {},
   "source": [
    "# #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e7a4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6538, 0.1818])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initially use a 27 --> 2 dimensional space; 27 characters in lexicon, 2 parameter embedding\n",
    "C = torch.randn((27, 2)) # random starting values, untrained\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0282613b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example encoding one row of the C lookup table\n",
    "example_row = F.one_hot(torch.tensor(5), num_classes=27).float() # expressly cast as float\n",
    "example_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b95eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6538, 0.1818])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row @ C  # output is identical to C[5] because as the first layer there is no nonlinearity\n",
    "# the effect if to take the C values for that row and embed them in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d01a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6538, 0.1818],\n",
       "        [0.6006, 0.4620],\n",
       "        [1.0696, 2.0331],\n",
       "        [1.0696, 2.0331],\n",
       "        [1.0696, 2.0331]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the first layer use the row values of C, since they are equivalent\n",
    "\n",
    "C[torch.tensor([5,6,7, 7, 7])] # rows can be repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9113d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape  # embeds the (27 , 2) matrix of value from #2 into the (32, 3) corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a663ed77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is the collection of 3 preceeding character indices: \n",
    "# (row corresponding to the latest character, three indices of the three preceeding characters)\n",
    "X[13, 2] # this is the 14th collection of three preceeding characters, from above: ..a ----> v\n",
    "# this returns the index for 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7dd2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6385, -0.9289])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][13, 2] # the embedding at the position for the (13, 2) character 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15fad074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6385, -0.9289])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1] # another way to access the  embedding for the first character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a63db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor([0.7421, 0.1760]), tensor([0.7421, 0.1760]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of the 0 character\n",
    "X[13, 1], C[0], C[X][13, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b11c87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices from X (the collection of 3 preceeding characters) are assigned the vectors \n",
    "# from C at those indices in C\n",
    "# leads to a shape of the number of 3 character values from X, made up of the \n",
    "# vectors of the characters at each of the index values in C of the values from X\n",
    "\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483008eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices for 'emm': tensor([ 5, 13, 13])\n",
      "vector embeddings for indices of X at 'emm':\n",
      " tensor([[ 0.6538,  0.1818],\n",
      "        [-0.3289, -0.2409],\n",
      "        [-0.3289, -0.2409]]) \n"
     ]
    }
   ],
   "source": [
    "print(f\"indices for 'emm': {X[3]}\")\n",
    "print(f\"vector embeddings for indices of X at 'emm':\\n {emb[3]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acd35a",
   "metadata": {},
   "source": [
    "### Hidden Layer: [page 6](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05db64c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 100]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# inputs to the hidden layer\n",
    "# 3 characters, 2 deep (as defined at C) --> 6 x 100 (100 assigned as choice)\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)\n",
    "print(W1.shape, b1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01cb2f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desired action: emb @ W + b  <-- shape is wrong; need (32, 6)\n",
    "# pulls out the C vectors for each position of the values of X\n",
    "# this code is hard coded to the block_size = 3 --> use torch.unbind\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf15943",
   "metadata": {},
   "source": [
    "#### Technique 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92a7a89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# torch.unbind extracts the values at the given dimension\n",
    "# (torch.unbind(emb, 1)) # produces 3 tuples: the 2D vectors from C for each of the characters in dimension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "916f9bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenates the 3 collections of C vectors for each value at dimension 1\n",
    "# this could be expanded with a larger block_size, which would be found at dimension 1\n",
    "# inefficient because a new tensor is created with cat\n",
    "\n",
    "emb2 = torch.cat(torch.unbind(emb, 1), 1)\n",
    "emb2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ef36b",
   "metadata": {},
   "source": [
    "#### Technique 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d81a4b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb3 = emb.view(32, 6) # more efficient was to re-assign values\n",
    "emb3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d168ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb2 == emb3   # elementwise comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b92f7",
   "metadata": {},
   "source": [
    "#### Generalized use of the Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87547326",
   "metadata": {},
   "source": [
    "Take the time to confirm the shape of the values:\n",
    "- emb.view(-1, 6) --> (32, 6)\n",
    "- W1 --> (6, 100)\n",
    "- b1 --> (,100) ; confirm the [broadcasting rules](https://pytorch.org/docs/stable/notes/broadcasting.html) ; trailing dimensions are equal --> b is broadcast across the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a10a8512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 length activations for each of the 32 samples\n",
    "h_ = emb.view(-1, 6) @ W1 + b1  # the -1 value leads pytorch to derive the value 32\n",
    "h = torch.tanh(h_)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a5c390",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Will derive the probabilities for the next character based on the input 3 character set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cc11fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27)) \n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1480735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "999964b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30dcfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities for each of 27 characters based on the preceeding 3 character values \n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56ba8389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), tensor(1.))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape, prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78888acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y's shape:  torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.5532e-15, 9.8704e-10, 3.7192e-05, 5.2907e-02, 4.0825e-04, 1.9278e-08,\n",
       "        7.3502e-14, 4.1476e-12, 1.6223e-10, 3.2840e-11, 2.7298e-10, 1.2534e-09,\n",
       "        3.5036e-08, 8.6059e-01, 2.3232e-05, 7.0813e-03, 7.7228e-13, 5.9000e-09,\n",
       "        8.2822e-01, 6.5854e-10, 8.3075e-16, 3.2893e-17, 1.8251e-11, 1.8070e-06,\n",
       "        4.0434e-04, 5.0777e-05, 8.6054e-09, 3.9314e-07, 1.1683e-04, 6.1279e-11,\n",
       "        1.0775e-11, 1.2653e-01])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the probability from prob at the index of Y\n",
    "# the closer to 1 the better trained the network is at predicting the correct Y\n",
    "\n",
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0090a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
