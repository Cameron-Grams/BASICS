{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8299726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/q8SA3rM6ckI?t=3217"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4926e",
   "metadata": {},
   "source": [
    "# Key Take-Aways:\n",
    "- Details of Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b4664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dbb58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2741e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# character - integer mappings\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f62f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset\n",
    "block_size = 3 # context length for characters\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]  # crop and create new context\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4232e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# training, dev and test sets\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "# break points for a 80, 10, 10 split\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01924f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison function for calculated gradient and pytorch gradient\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17c96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters (b1 and b2) n non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e06d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae4451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3306, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "#2\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "    for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "        norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "        bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "        embcat, emb]:\n",
    "        t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b4744f",
   "metadata": {},
   "source": [
    "## Derivations of the backpropagation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68b644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# differentiation of the log probabilities for the 27 values produced by the network\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)  # 0s in the shape of logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0/n # setting the correct indices of the logprobs to -1/n\n",
    "cmp('logprobs', dlogprobs, logprobs) # compares the dlogprobs values to those calculated by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0970efcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# derivative of the log function * derivative of the differentiated log probs \n",
    "# chain rule\n",
    "dprobs = (1.0/probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4243cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# differentiate into counts (32, 27) and counts_sum_inv (32, 1)\n",
    "# implied operation of duplicating counts_sum_inv to perform elementwise multiplication \n",
    "\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # the columns of counts each have the counts_sum_inv\n",
    "# value, in differentiation the values are added as per the chain rule\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89bde2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# differentiate for counts (other factor of probs)\n",
    "\n",
    "dcounts = counts_sum_inv * dprobs # chain rule at probs (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbcd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1b3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to differentiate the counts 2 branches must be accounted for: prior (#1) and after counts_sum\n",
    "# print(counts.shape)\n",
    "# print(counts_sum.shape)\n",
    "dcounts  += torch.ones_like(counts) * dcounts_sum  # broadcast the counts values into counts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9639c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ddfde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of norm logits; since the value is .exp the same value (counts) is used\n",
    "\n",
    "dnorm_logits = counts * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddbf6740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d4930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again logits is the second value in the network flow\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d38d7c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03928902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_maxes are small values --> near no impact on the change of the final loss\n",
    "# dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f30d61ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4503175360>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2; second branch of logits\n",
    "# print(logits.max(1, keepdim=True)) # max value per row plus the indices of the value\n",
    "\n",
    "# unpack the indices values across sized matrix; 1 in proper index, 0 otherwise; broadcast the \n",
    "# dlogit_maxes into this larger matrix shape\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes \n",
    "\n",
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fffbd18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaf70d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear of the logits; logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# study the shapes of the values involved\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0) # the dimension that you want to remove... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6358c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd7d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
